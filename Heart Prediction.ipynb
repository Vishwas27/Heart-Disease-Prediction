{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNAMING : \\nage = (21, 86)\\n\\nbp = blood pressure\\nch = Cholestrol\\nbs = blood sugar\\nphr = peak heart rate\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NAMING : \n",
    "age = (21, 86)\n",
    "\n",
    "bp = blood pressure\n",
    "ch = Cholestrol\n",
    "bs = blood sugar\n",
    "phr = peak heart rate\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uFCyt-Puq4K"
   },
   "outputs": [],
   "source": [
    "# Install the Antigranular package\n",
    "!pip install antigranular &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "w_JcMMSMv_Ze",
    "outputId": "bfc3bcfa-c84c-48c9-9271-06b4ec7df403"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tls_cert_name: ip-100-100-16-117.eu-west-1.compute.internal_a27c2555-be8f-484f-9d91-bd1e5cb3787e\n",
      "cert_thumbprint: 9b1551d6aeb735eda260edf6ad3acb7a41dbb33bf8d592dcb582f380563b42843aa5ce7297d43cf699c9b7cd904225d33e4a3d0c14bf868e95aa96a07b5f97b9\n",
      "server_hostname: ip-100-100-16-117.eu-west-1.compute.internal\n",
      "local_host_port: a27c2555-be8f-484f-9d91-bd1e5cb3787e\n",
      "Dataset \"Heart Disease Prediction Hackathon Dataset\" loaded to the kernel as \u001b[92mheart_disease_prediction_hackathon_dataset\u001b[0m\n",
      "Key Name                       Value Type     \n",
      "---------------------------------------------\n",
      "train_y                        PrivateDataFrame\n",
      "train_x                        PrivateDataFrame\n",
      "test_x                         DataFrame      \n",
      "\n",
      "Connected to Antigranular server session id: e8bf71bf-40f9-41f5-9113-2da9abc55c92, the session will time out if idle for 25 minutes\n",
      "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n",
      "🚀 Everything's set up and ready to roll!\n"
     ]
    }
   ],
   "source": [
    "import antigranular as ag\n",
    "session = ag.login(\"i7J4ws+if1W667ZAS29k00u04NZawE6j\", \"PpWDd8eF0gwlRxuMGYcGifT80fXuOcZ2L4sXPWJOusiPZi0YIyMUKUntMWVjPduj\", competition = \"Heart Disease Prediction Hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting onnxruntime\n",
      "  Downloading onnxruntime-1.18.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.3 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.6 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxruntime) (1.23.5)\n",
      "Requirement already satisfied: packaging in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxruntime) (23.0)\n",
      "Requirement already satisfied: protobuf in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxruntime) (1.11.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Downloading onnxruntime-1.18.1-cp311-cp311-macosx_11_0_universal2.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the Antigranular package\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting skl2onnx\n",
      "  Downloading skl2onnx-1.17.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: onnx>=1.2.1 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from skl2onnx) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from skl2onnx) (1.2.2)\n",
      "Collecting onnxconverter-common>=1.7.0 (from skl2onnx)\n",
      "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnx>=1.2.1->skl2onnx) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnx>=1.2.1->skl2onnx) (3.20.3)\n",
      "Requirement already satisfied: packaging in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from onnxconverter-common>=1.7.0->skl2onnx) (23.0)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.2.1->skl2onnx)\n",
      "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.1->skl2onnx) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.1->skl2onnx) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.1->skl2onnx) (2.2.0)\n",
      "Downloading skl2onnx-1.17.0-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: protobuf, onnxconverter-common, skl2onnx\n",
      "  Attempting uninstall: protobuf\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "antigranular 0.3.0 requires pandas<2.0.0,>=1.5.3; python_version >= \"3.8\" and python_version < \"3.12\", which is not installed.\n",
      "tensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed onnxconverter-common-1.14.0 protobuf-3.20.2 skl2onnx-1.17.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Users/vishwaschhimpa/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the Antigranular package\n",
    "!pip install skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "8IHVwjFKk2Ys"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "x_train = heart_disease_prediction_hackathon_dataset[\"train_x\"]\n",
    "y_train = heart_disease_prediction_hackathon_dataset[\"train_y\"]\n",
    "x_test = heart_disease_prediction_hackathon_dataset[\"test_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMiVe3n_t4um",
    "outputId": "100ed641-8623-442b-c346-ae081d2d7742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------------+---------------+---------+------------+\n",
      "|    | Column   | numerical   | categorical   | dtype   | bounds     |\n",
      "|----+----------+-------------+---------------+---------+------------|\n",
      "|  0 | age      | True        | False         | int64   | (21, 86)   |\n",
      "|  1 | sex      | True        | False         | int64   | (0, 1)     |\n",
      "|  2 | bp       | True        | False         | int64   | (80, 215)  |\n",
      "|  3 | ch       | True        | False         | int64   | (102, 597) |\n",
      "|  4 | bs       | True        | False         | int64   | (67, 157)  |\n",
      "|  5 | phr      | True        | False         | int64   | (62, 222)  |\n",
      "+----+----------+-------------+---------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag # join with series\n",
    "result = x_train.join(y_train,how=\"inner\")\n",
    "ag_print(\"Inner Join of PDF and Series Describe:\\n\",result.describe(eps=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "ag_print(result.corr(eps = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONDITION VARYING WITH BP, BS , CH and PHR, AGE, SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "ag_print(x_train.corr(eps = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# We can start by exploring the data, carefully using our epsilon\n",
    "describe = x_train.describe(eps=0.1)\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATING SYNTHETIC DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic healthcare data\n",
    "def generate_synthetic_data(num_samples=10000):\n",
    "    np.random.seed(0)\n",
    "    ages = np.random.randint(21, 86, num_samples)\n",
    "    blood_pressures = np.random.normal(120, 20, num_samples).astype(int)\n",
    "    cholesterols = np.random.normal(200, 50, num_samples).astype(int)\n",
    "\n",
    "    diagnosis = []\n",
    "    for i in range(num_samples):\n",
    "        age_factor = (ages[i] - 21) / 65\n",
    "        bp_factor = (blood_pressures[i] - 60) / 120\n",
    "        chol_factor = (cholesterols[i] - 100) / 200\n",
    "        score = 0.3 * age_factor + 0.4 * bp_factor + 0.3 * chol_factor + np.random.rand() * 0.1\n",
    "        diagnosis.append(1 if score > 0.5 else 0)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"PatientID\": range(1, num_samples + 1),\n",
    "        \"Age\": ages,\n",
    "        \"BloodPressure\": blood_pressures,\n",
    "        \"Cholesterol\": cholesterols,\n",
    "        \"Diagnosis\": diagnosis\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG3HnW1Ut8X2",
    "outputId": "499571aa-cc92-4fa5-8e62-f336af125357"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QNyLhdXmYs5",
    "outputId": "9d265ad3-2309-480a-b536-17f92a220d92"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# We can start by exploring the data, carefully using our epsilon\n",
    "describe = x_train.describe(eps=0.1)\n",
    "ag_print(describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJ4MX9Ghs2z6",
    "outputId": "fa2b17a7-186c-4919-a6b1-cfc1227d942f"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# We can start by exploring the data, carefully using our epsilon\n",
    "describe = y_train.describe(eps=0.1)\n",
    "ag_print(describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "\n",
    "ag_print(x_train.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "\n",
    "ag_print(x_train.corr(eps = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "\n",
    "ag_print(x_test.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "# x_test is a public test set, so we can print it without using epsilon\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OymOmMhqmzpK",
    "outputId": "c2407882-5771-454d-d517-c00d3b27e56f"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# x_test is a public test set, so we can print it without using epsilon\n",
    "ag_print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KARrFlm5pOB6"
   },
   "source": [
    "### 🎈 A quick solution\n",
    "\n",
    "In this section we evaluate an editorial solution in AG using TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVMog5sFunqk",
    "outputId": "20089257-81f7-4284-d1b1-d3020fab4fba"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "import tensorflow as tf\n",
    "from op_pandas import standard_scaler, PrivateDataFrame\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from op_tensorflow import PrivateKerasModel, PrivateDataLoader\n",
    "\n",
    "\n",
    "# Normal keras model\n",
    "seqM = Sequential([\n",
    "    Dense(32, activation='tanh', input_shape=(6,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Create DP keras model\n",
    "dp_model = PrivateKerasModel(model=seqM, l2_norm_clip=1, noise_multiplier=1.5)\n",
    "\n",
    "# Use a standard (non-DP) optimizer directly from keras.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# PrivateKerasModel uses similar API as standard Keras\n",
    "dp_model.compile(\n",
    "\toptimizer = optimizer,\n",
    "\tloss = 'binary_crossentropy',\n",
    "\tmetrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtZnkEIGu4Oy",
    "outputId": "9b65d460-abfb-47e3-b99d-2501eadfadcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------------+---------------+---------+------------------------------------------+\n",
      "|    | Column   | numerical   | categorical   | dtype   | bounds                                   |\n",
      "|----+----------+-------------+---------------+---------+------------------------------------------|\n",
      "|  0 | age      | True        | False         | float64 | (-3.5766187299396734,                    |\n",
      "|    |          |             |               |         | 3.0769021807809898)                      |\n",
      "|  1 | sex      | True        | False         | float64 | (-1.4484021171450685,                    |\n",
      "|    |          |             |               |         | 0.7094310966210944)                      |\n",
      "|  2 | bp       | True        | False         | float64 | (-1.2962994967024581, 1.909019052861088) |\n",
      "|  3 | ch       | True        | False         | float64 | (-3.848508234765949, 8.846062328873685)  |\n",
      "|  4 | bs       | True        | False         | float64 | (-1.5488682949931336,                    |\n",
      "|    |          |             |               |         | 2.2468164388952987)                      |\n",
      "|  5 | phr      | True        | False         | float64 | (-3.521171728780882, 3.0330499803028874) |\n",
      "+----+----------+-------------+---------------+---------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "x_train_scaled = standard_scaler(x_train, eps=.1)\n",
    "x_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-IRE6nbYvcw7"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "data_loader = PrivateDataLoader(feature_df=x_train_scaled , label_df=y_train, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### %%ag\n",
    "from op_tensorflow import get_privacy_budget\n",
    "get_privacy_budget(\n",
    "    sample_size=25000,\n",
    "    batch_size=25,\n",
    "    num_epochs=25,\n",
    "    noise_multiplier=1.5,\n",
    "    target_delta=1e-5, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkYeXE1nv0EL",
    "outputId": "13e357f7-0663-45bd-88ab-b6124beeaf85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "1000/1000 - 16s - loss: 0.3494 - accuracy: 0.8360 - 16s/epoch - 16ms/step\n",
      "\n",
      "Epoch 2/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3407 - accuracy: 0.8437 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 3/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3390 - accuracy: 0.8438 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 4/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3305 - accuracy: 0.8490 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 5/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3259 - accuracy: 0.8501 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 6/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3230 - accuracy: 0.8494 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 7/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3254 - accuracy: 0.8544 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 8/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3333 - accuracy: 0.8445 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 9/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3181 - accuracy: 0.8547 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 10/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3223 - accuracy: 0.8559 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 11/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3152 - accuracy: 0.8601 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 12/25\n",
      "\n",
      "1000/1000 - 17s - loss: 0.3118 - accuracy: 0.8630 - 17s/epoch - 17ms/step\n",
      "\n",
      "Epoch 13/25\n",
      "\n",
      "1000/1000 - 16s - loss: 0.3225 - accuracy: 0.8580 - 16s/epoch - 16ms/step\n",
      "\n",
      "Epoch 14/25\n",
      "\n",
      "1000/1000 - 15s - loss: 0.3066 - accuracy: 0.8632 - 15s/epoch - 15ms/step\n",
      "\n",
      "Epoch 15/25\n",
      "\n",
      "1000/1000 - 15s - loss: 0.3104 - accuracy: 0.8608 - 15s/epoch - 15ms/step\n",
      "\n",
      "Epoch 16/25\n",
      "\n",
      "1000/1000 - 15s - loss: 0.3058 - accuracy: 0.8683 - 15s/epoch - 15ms/step\n",
      "\n",
      "Epoch 17/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3048 - accuracy: 0.8643 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 18/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3072 - accuracy: 0.8668 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 19/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3130 - accuracy: 0.8606 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 20/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3112 - accuracy: 0.8632 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 21/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.2979 - accuracy: 0.8656 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 22/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3048 - accuracy: 0.8659 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 23/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3098 - accuracy: 0.8671 - 14s/epoch - 14ms/step\n",
      "\n",
      "Epoch 24/25\n",
      "\n",
      "1000/1000 - 15s - loss: 0.3037 - accuracy: 0.8673 - 15s/epoch - 15ms/step\n",
      "\n",
      "Epoch 25/25\n",
      "\n",
      "1000/1000 - 14s - loss: 0.3063 - accuracy: 0.8652 - 14s/epoch - 14ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "dp_model.fit(x=data_loader, epochs=25, target_delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt_0vemmvq17",
    "outputId": "d2ebe4a3-01aa-4923-805c-8702feb2d7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 5s\n",
      " 8/63 [==>...........................] - ETA: 0s\n",
      "27/63 [===========>..................] - ETA: 0s\n",
      "47/63 [=====================>........] - ETA: 0s\n",
      "63/63 [==============================] - 0s 5ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "x_test_scaler = standard_scaler(PrivateDataFrame(x_test), eps=.2)\n",
    "y_pred = dp_model.predict(x_test_scaler, label_columns=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mJMoynKBAwMB"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# Note that the predictions are a float scalar\n",
    "# so we scale it\n",
    "def f(x: float) -> float:\n",
    "  if x > 0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "y_pred[\"output\"] = y_pred[\"output\"].map(f, output_bounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikoa-r-Ky79A",
    "outputId": "4f9f7cc0-689d-47d1-a0d7-9f0c6f621c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Last submission done under 5 minutes ago\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "result = submit_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzIEcXX6unAN"
   },
   "source": [
    "### 🎈 Another quick solution\n",
    "\n",
    "In this section we evaluate an editorial solution in AG using Diffprivlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "G4ek0zLhmqNm"
   },
   "outputs": [],
   "source": [
    "%%ag\n",
    "# We can follow by importing the OP (\"Oblivious Private\") version of diffprivlib\n",
    "from op_diffprivlib.models import LinearRegression,LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "p3ECSjJzSX3l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/dependencies/ag_wrapper/ag_wrapper/wrapper.py:129: UserWarning: Bounds estimation epsilon is set to 0.1. It wont be charged until a private dataframe / series ispassed to predict or transform methods.\n",
      "  warnings.warn(f\"Bounds estimation epsilon is set to {bounds_estimation_eps}. It wont be charged until \"\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "# We can generate a quick regression using epsilon\n",
    "reg = LogisticRegression(epsilon=0.1,data_norm=7.89)\n",
    "\n",
    "# Fit it with 3 of the SNP predictors\n",
    "reg.fit(x_train[[\"bp\", \"ch\", \"bs\", \"phr\",\"age\" ]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "cMn0AhQpnI5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "# Predict with the same features\n",
    "y_pred = reg.predict(x_test[[\"bp\", \"ch\", \"bs\", \"phr\",\"age\"]])\n",
    "\n",
    "# Print the result\n",
    "ag_print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r7em_XGnsyD"
   },
   "source": [
    "### 📩 Export your prediction\n",
    "\n",
    "We take the prediciton out of AG to later send it to the leaderboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "O7uUnjkhnz61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Last submission done under 5 minutes ago\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "import pandas as pd\n",
    "# Submit prediction\n",
    "result = submit_predictions(pd.DataFrame(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.terminate_session()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
